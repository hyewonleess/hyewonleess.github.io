---
title:  "[Feature Selection] #3. SHAP"
categories:
  - theory
tags:
  - feature selection
  - SHAP
  - modeling
toc: true
use_math: true
sitemap: 
---

Feature selection 시리즈 포스팅의 마지막! 이번 포스팅에서는 Kaggle과 같은 데이터분석 플랫폼에서도 많이 쓰이는 SHAP에 대해 다룬다.

## Introduction to SHAP
<mark style='background-color: #fff5b1'> SHAP </mark>은 머신러닝에서 feature의 영향/효과를 계산할 때 사용하는 방법으로, 게임이론에 등장하는 **shapley value**를 바탕으로 목적변수에 대한 각 feature의 영향이 측정된다. 이전 포스팅에서 다룬 Permutation importance와 다른 점은, permutation importance는 모델의 성능이 얼마나 떨어지는지에 따라 변수 중요도를 측정하고 feature을 선택하지만 SHAP은 변수가 목적변수에 미치는 영향을 기준으로 선택한다.


## 1. Shapley value
SHAP에 대해 이해하기 위해선 게임이론의 shapley value에 대한 이해가 선행되어야 한다. Shapley value의 기본 아이디어는 모든 변수 조건 조합에서 특정 변수가 미치는 영향(marginal contribution)을 측정하는 것이다! 말로만 설명하면 이해하기 어렵기 때문에 간단한 예시와 함께 살펴보자.
<br>
### (1) Example: Hotel price
호텔 가격을 책정하는데 다음과 같은 요소들이 고려된다고 가정하자: **주변에 공원 여부, 면적 100, 3층, 반려동물 허용 여부** <br>
여기서 우리는 **반려동물 허용여부**가 목적변수인 호텔 가격에 미치는 영향을 측정하는 것이 목표이다. '반려동물 허용여부'를 제외한 다른 변수들은 다음과 8개의 경우로 조합될 수 있다.
 + no feature
 + 주변 공원여부
 + 면적 100
 + 3층
 + 주변 공원여부, 면적 100
 + 주변 공원여부, 3층
 + 면적 100, 3층
 + 주변 공원여부, 면적 100, 3층
<br>
각 변수 조합에 따라 '반려동물 허용여부'가 호텔 가격에 미치는 영향의 marginal contribution을 계산하여 가중평균을 내면 '반려동물 허용여부'의 영향을 계산할 수 있다.
